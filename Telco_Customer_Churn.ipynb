{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMK/uqfbs0EgLuX54J0D7H2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/milochanarathnayake24/DataScienceProjects_24/blob/main/Telco_Customer_Churn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "DfecrMWmMUJQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Load dataset (assuming X_train, X_test, y_train, y_test are already split)\n",
        "# Replace 'Churn' with your actual target column name if different\n",
        "X = pd.read_csv('/content/telco_churn.csv')\n",
        "y = X['Churn']\n",
        "X = X.drop('Churn', axis=1)\n",
        "\n",
        "# Identify categorical and numerical columns\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns\n",
        "numerical_cols = X.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "# Define preprocessing steps\n",
        "numerical_transformer = StandardScaler()\n",
        "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)\n",
        "    ])\n",
        "\n",
        "# Define the pipeline with preprocessing and model building\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply preprocessing pipeline to training data\n",
        "X_train = pipeline.fit_transform(X_train)\n",
        "X_test = pipeline.transform(X_test)\n"
      ],
      "metadata": {
        "id": "DQmZsATVN15B"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Convert sparse matrices to dense arrays\n",
        "X_train = X_train.toarray()\n",
        "X_test = X_test.toarray()\n",
        "\n",
        "# Now you can proceed with model training\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynyA_qFGTGA8",
        "outputId": "867708cc-828a-4dd5-9739-05f5df5732eb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "83/83 [==============================] - 2s 8ms/step - loss: 0.3433 - accuracy: 0.8558 - val_loss: 0.2255 - val_accuracy: 0.8894\n",
            "Epoch 2/50\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.2235 - accuracy: 0.8980 - val_loss: 0.2119 - val_accuracy: 0.8909\n",
            "Epoch 3/50\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.1873 - accuracy: 0.9196 - val_loss: 0.2124 - val_accuracy: 0.8939\n",
            "Epoch 4/50\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.1372 - accuracy: 0.9484 - val_loss: 0.2133 - val_accuracy: 0.9045\n",
            "Epoch 5/50\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 0.0725 - accuracy: 0.9886 - val_loss: 0.2426 - val_accuracy: 0.8773\n",
            "Epoch 6/50\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 0.0266 - accuracy: 0.9992 - val_loss: 0.2393 - val_accuracy: 0.8864\n",
            "Epoch 7/50\n",
            "83/83 [==============================] - 0s 6ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.2352 - val_accuracy: 0.8833\n",
            "Epoch 8/50\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.2437 - val_accuracy: 0.8818\n",
            "Epoch 9/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2566 - val_accuracy: 0.8803\n",
            "Epoch 10/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2512 - val_accuracy: 0.8788\n",
            "Epoch 11/50\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2638 - val_accuracy: 0.8803\n",
            "Epoch 12/50\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2700 - val_accuracy: 0.8803\n",
            "Epoch 13/50\n",
            "83/83 [==============================] - 1s 10ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2639 - val_accuracy: 0.8788\n",
            "Epoch 14/50\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 8.0363e-04 - accuracy: 1.0000 - val_loss: 0.2663 - val_accuracy: 0.8818\n",
            "Epoch 15/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 6.6317e-04 - accuracy: 1.0000 - val_loss: 0.2689 - val_accuracy: 0.8803\n",
            "Epoch 16/50\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 5.5054e-04 - accuracy: 1.0000 - val_loss: 0.2739 - val_accuracy: 0.8773\n",
            "Epoch 17/50\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 4.6736e-04 - accuracy: 1.0000 - val_loss: 0.2728 - val_accuracy: 0.8758\n",
            "Epoch 18/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 3.9852e-04 - accuracy: 1.0000 - val_loss: 0.2762 - val_accuracy: 0.8773\n",
            "Epoch 19/50\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 3.4410e-04 - accuracy: 1.0000 - val_loss: 0.2768 - val_accuracy: 0.8758\n",
            "Epoch 20/50\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 3.0027e-04 - accuracy: 1.0000 - val_loss: 0.2798 - val_accuracy: 0.8742\n",
            "Epoch 21/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 2.6372e-04 - accuracy: 1.0000 - val_loss: 0.2743 - val_accuracy: 0.8788\n",
            "Epoch 22/50\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 2.3314e-04 - accuracy: 1.0000 - val_loss: 0.2792 - val_accuracy: 0.8773\n",
            "Epoch 23/50\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 2.0690e-04 - accuracy: 1.0000 - val_loss: 0.2837 - val_accuracy: 0.8742\n",
            "Epoch 24/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 1.8457e-04 - accuracy: 1.0000 - val_loss: 0.2786 - val_accuracy: 0.8803\n",
            "Epoch 25/50\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 1.6596e-04 - accuracy: 1.0000 - val_loss: 0.2819 - val_accuracy: 0.8773\n",
            "Epoch 26/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 1.4906e-04 - accuracy: 1.0000 - val_loss: 0.2778 - val_accuracy: 0.8773\n",
            "Epoch 27/50\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 1.3464e-04 - accuracy: 1.0000 - val_loss: 0.2841 - val_accuracy: 0.8758\n",
            "Epoch 28/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 1.2222e-04 - accuracy: 1.0000 - val_loss: 0.2882 - val_accuracy: 0.8742\n",
            "Epoch 29/50\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 1.1125e-04 - accuracy: 1.0000 - val_loss: 0.2857 - val_accuracy: 0.8758\n",
            "Epoch 30/50\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 1.0137e-04 - accuracy: 1.0000 - val_loss: 0.2930 - val_accuracy: 0.8727\n",
            "Epoch 31/50\n",
            "83/83 [==============================] - 1s 6ms/step - loss: 9.2877e-05 - accuracy: 1.0000 - val_loss: 0.2887 - val_accuracy: 0.8742\n",
            "Epoch 32/50\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 8.5070e-05 - accuracy: 1.0000 - val_loss: 0.2884 - val_accuracy: 0.8758\n",
            "Epoch 33/50\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 7.8178e-05 - accuracy: 1.0000 - val_loss: 0.2921 - val_accuracy: 0.8742\n",
            "Epoch 34/50\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 7.2050e-05 - accuracy: 1.0000 - val_loss: 0.2886 - val_accuracy: 0.8788\n",
            "Epoch 35/50\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 6.6345e-05 - accuracy: 1.0000 - val_loss: 0.2921 - val_accuracy: 0.8758\n",
            "Epoch 36/50\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 6.1298e-05 - accuracy: 1.0000 - val_loss: 0.2948 - val_accuracy: 0.8742\n",
            "Epoch 37/50\n",
            "83/83 [==============================] - 1s 7ms/step - loss: 5.6748e-05 - accuracy: 1.0000 - val_loss: 0.2949 - val_accuracy: 0.8742\n",
            "Epoch 38/50\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 5.2590e-05 - accuracy: 1.0000 - val_loss: 0.2934 - val_accuracy: 0.8758\n",
            "Epoch 39/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 4.8801e-05 - accuracy: 1.0000 - val_loss: 0.2941 - val_accuracy: 0.8742\n",
            "Epoch 40/50\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 4.5419e-05 - accuracy: 1.0000 - val_loss: 0.2976 - val_accuracy: 0.8742\n",
            "Epoch 41/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 4.2303e-05 - accuracy: 1.0000 - val_loss: 0.2980 - val_accuracy: 0.8742\n",
            "Epoch 42/50\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 3.9392e-05 - accuracy: 1.0000 - val_loss: 0.2958 - val_accuracy: 0.8758\n",
            "Epoch 43/50\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 3.6790e-05 - accuracy: 1.0000 - val_loss: 0.2999 - val_accuracy: 0.8727\n",
            "Epoch 44/50\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 3.4342e-05 - accuracy: 1.0000 - val_loss: 0.2974 - val_accuracy: 0.8742\n",
            "Epoch 45/50\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 3.2141e-05 - accuracy: 1.0000 - val_loss: 0.3016 - val_accuracy: 0.8697\n",
            "Epoch 46/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 3.0015e-05 - accuracy: 1.0000 - val_loss: 0.3011 - val_accuracy: 0.8742\n",
            "Epoch 47/50\n",
            "83/83 [==============================] - 0s 4ms/step - loss: 2.8139e-05 - accuracy: 1.0000 - val_loss: 0.3018 - val_accuracy: 0.8727\n",
            "Epoch 48/50\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 2.6359e-05 - accuracy: 1.0000 - val_loss: 0.3032 - val_accuracy: 0.8727\n",
            "Epoch 49/50\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 2.4728e-05 - accuracy: 1.0000 - val_loss: 0.3012 - val_accuracy: 0.8742\n",
            "Epoch 50/50\n",
            "83/83 [==============================] - 0s 5ms/step - loss: 2.3234e-05 - accuracy: 1.0000 - val_loss: 0.3036 - val_accuracy: 0.8727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate Model Performance**\n",
        "After training your model using model.fit(), you can evaluate its performance using the test data (X_test and y_test). This step helps you understand how well your model generalizes to unseen data."
      ],
      "metadata": {
        "id": "jFwYhXtNTsMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model on test data\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss:.4f}')\n",
        "print(f'Test Accuracy: {accuracy:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXFVkbNxTmkN",
        "outputId": "b1449426-b640-45bd-c6d1-26f7a33738c5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26/26 [==============================] - 0s 2ms/step - loss: 0.2657 - accuracy: 0.8885\n",
            "Test Loss: 0.2657\n",
            "Test Accuracy: 0.8885\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpret the Results**\n",
        "Interpret the evaluation results to understand how well your model performed. Key metrics to consider include loss (typically cross-entropy loss for binary classification) and accuracy. You might also look at additional metrics like precision, recall, and F1-score if applicable."
      ],
      "metadata": {
        "id": "3aWssm2ATxD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of printing additional metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2yPYIxzT1Pf",
        "outputId": "ab94cc4a-0f33-4fd4-d075-4f2d4e6d473e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26/26 [==============================] - 0s 3ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.91      0.93       724\n",
            "           1       0.53      0.75      0.62       101\n",
            "\n",
            "    accuracy                           0.89       825\n",
            "   macro avg       0.75      0.83      0.78       825\n",
            "weighted avg       0.91      0.89      0.90       825\n",
            "\n",
            "[[657  67]\n",
            " [ 25  76]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fine-tune the Model (Optional)**\n",
        "Based on the evaluation results, you might decide to fine-tune your model by adjusting hyperparameters (e.g., learning rate, number of epochs), tweaking the model architecture (e.g., adding/removing layers, adjusting layer sizes), or exploring regularization techniques (e.g., dropout)."
      ],
      "metadata": {
        "id": "ydA9FIE_T0od"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the entire model to a HDF5 file\n",
        "model.save('customer_churn_model.h5')\n",
        "\n",
        "# Later you can load the model using:\n",
        "# loaded_model = tf.keras.models.load_model('customer_churn_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5j9k__QEUAQ_",
        "outputId": "6c3278ee-1aad-4777-8e57-ba5ad50205d6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    }
  ]
}